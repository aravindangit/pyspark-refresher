{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8e3857-a376-412c-b7f5-b32fd68d163a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import col\n",
    "from delta.tables import DeltaTable\n",
    "from datetime import date\n",
    "\n",
    "# Sample data for the updates with customerId, new address, and effective date of the change\n",
    "updates_data = [\n",
    "    (1, 'kumar street', date(2023, 6, 17)),\n",
    "    (3, 'porur street', date(2023, 6, 17)),\n",
    "    (6, 'thuvarnkuruchi street', date(2023, 6, 17)),\n",
    "    (7, 'thiruvanmiyur street', date(2023, 6, 17))\n",
    "]\n",
    "\n",
    "# Define schema for the updates DataFrame\n",
    "updates_schema = StructType([\n",
    "    StructField(\"customerId\", IntegerType(), False),\n",
    "    StructField(\"address\", StringType(), False),\n",
    "    StructField(\"effectiveDate\", DateType(), False)\n",
    "])\n",
    "\n",
    "# Create DataFrame for updates using the sample data and schema\n",
    "updates_df = spark.createDataFrame(updates_data, updates_schema)\n",
    "\n",
    "# Define the Delta table name where customer data is stored\n",
    "delta_table_name = \"customers_scd1\"\n",
    "\n",
    "# Check if the Delta table exists in the metastore\n",
    "if not spark.catalog.tableExists(delta_table_name):\n",
    "    # If table does not exist, prepare initial data from updates\n",
    "    initial_data = [(row.customerId, row.address, row.effectiveDate) for row in updates_df.collect()]\n",
    "\n",
    "    # Define schema for the initial data\n",
    "    initial_schema = StructType([\n",
    "        StructField(\"customerId\", IntegerType(), False),\n",
    "        StructField(\"address\", StringType(), False),\n",
    "        StructField(\"effectiveDate\", DateType(), False)\n",
    "    ])\n",
    "\n",
    "    # Create DataFrame for initial data to seed the Delta table\n",
    "    initial_df = spark.createDataFrame(initial_data, initial_schema)\n",
    "\n",
    "    # Write the initial DataFrame to a new Delta table, overwriting if exists\n",
    "    initial_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(delta_table_name)\n",
    "\n",
    "# Load the existing Delta table as a DeltaTable object for merge operations\n",
    "customersTable = DeltaTable.forName(spark, delta_table_name)\n",
    "\n",
    "# Perform SCD Type 1 merge:\n",
    "# - When matched, update the address and effectiveDate\n",
    "# - When not matched, insert new record\n",
    "customersTable.alias(\"customers\").merge(\n",
    "    updates_df.alias(\"updates\"),\n",
    "    \"customers.customerId = updates.customerId\"\n",
    ").whenMatchedUpdate(\n",
    "    set={\n",
    "        \"address\": col(\"updates.address\"),\n",
    "        \"effectiveDate\": col(\"updates.effectiveDate\")\n",
    "    }\n",
    ").whenNotMatchedInsert(\n",
    "    values={\n",
    "        \"customerId\": col(\"updates.customerId\"),\n",
    "        \"address\": col(\"updates.address\"),\n",
    "        \"effectiveDate\": col(\"updates.effectiveDate\")\n",
    "    }\n",
    ").execute()\n",
    "\n",
    "# Display the final state of the Delta table after applying updates\n",
    "display(customersTable.toDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcf351b4-53df-40c9-8c1f-c974c6e12391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from workspace.default.customers_scd1"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2452249984626017,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "scd type 1 implemetation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
